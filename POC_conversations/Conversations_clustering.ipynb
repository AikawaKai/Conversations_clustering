{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d71712ef-8647-4906-b7cd-e67dd8722276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: umap-learn in c:\\users\\marcoodore\\anaconda3\\lib\\site-packages (0.5.5)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\marcoodore\\anaconda3\\lib\\site-packages (from umap-learn) (1.26.3)\n",
      "Requirement already satisfied: scipy>=1.3.1 in c:\\users\\marcoodore\\anaconda3\\lib\\site-packages (from umap-learn) (1.11.4)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in c:\\users\\marcoodore\\anaconda3\\lib\\site-packages (from umap-learn) (1.3.0)\n",
      "Requirement already satisfied: numba>=0.51.2 in c:\\users\\marcoodore\\anaconda3\\lib\\site-packages (from umap-learn) (0.58.1)\n",
      "Requirement already satisfied: pynndescent>=0.5 in c:\\users\\marcoodore\\anaconda3\\lib\\site-packages (from umap-learn) (0.5.11)\n",
      "Requirement already satisfied: tqdm in c:\\users\\marcoodore\\anaconda3\\lib\\site-packages (from umap-learn) (4.65.0)\n",
      "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in c:\\users\\marcoodore\\anaconda3\\lib\\site-packages (from numba>=0.51.2->umap-learn) (0.41.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\marcoodore\\anaconda3\\lib\\site-packages (from pynndescent>=0.5->umap-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\marcoodore\\anaconda3\\lib\\site-packages (from scikit-learn>=0.22->umap-learn) (2.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\marcoodore\\anaconda3\\lib\\site-packages (from tqdm->umap-learn) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install umap-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e22149aa-a11b-4bcf-8ffb-352196d2f631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fast_hdbscan in c:\\users\\marcoodore\\anaconda3\\lib\\site-packages (0.1.3)\n",
      "Requirement already satisfied: numpy>=1.21 in c:\\users\\marcoodore\\anaconda3\\lib\\site-packages (from fast_hdbscan) (1.26.3)\n",
      "Requirement already satisfied: numba>=0.56 in c:\\users\\marcoodore\\anaconda3\\lib\\site-packages (from fast_hdbscan) (0.58.1)\n",
      "Requirement already satisfied: scikit-learn>=1.1 in c:\\users\\marcoodore\\anaconda3\\lib\\site-packages (from fast_hdbscan) (1.3.0)\n",
      "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in c:\\users\\marcoodore\\anaconda3\\lib\\site-packages (from numba>=0.56->fast_hdbscan) (0.41.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\marcoodore\\anaconda3\\lib\\site-packages (from scikit-learn>=1.1->fast_hdbscan) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\marcoodore\\anaconda3\\lib\\site-packages (from scikit-learn>=1.1->fast_hdbscan) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\marcoodore\\anaconda3\\lib\\site-packages (from scikit-learn>=1.1->fast_hdbscan) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install fast_hdbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16718b7d-e1f9-4f97-8350-714d734c7288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hdbscan in c:\\users\\marcoodore\\anaconda3\\lib\\site-packages (0.8.33)\n",
      "Requirement already satisfied: cython<3,>=0.27 in c:\\users\\marcoodore\\anaconda3\\lib\\site-packages (from hdbscan) (0.29.37)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\marcoodore\\anaconda3\\lib\\site-packages (from hdbscan) (1.26.3)\n",
      "Requirement already satisfied: scipy>=1.0 in c:\\users\\marcoodore\\anaconda3\\lib\\site-packages (from hdbscan) (1.11.4)\n",
      "Requirement already satisfied: scikit-learn>=0.20 in c:\\users\\marcoodore\\anaconda3\\lib\\site-packages (from hdbscan) (1.3.0)\n",
      "Requirement already satisfied: joblib>=1.0 in c:\\users\\marcoodore\\anaconda3\\lib\\site-packages (from hdbscan) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\marcoodore\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20->hdbscan) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install hdbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f3df02f-322a-4066-b703-badb857c4e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import umap\n",
    "import numpy as np\n",
    "import hdbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "346efe59-8f07-4ff0-a811-a1510c33b4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"embedding.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "320fd4bb-96ca-4689-b351-0942766f58b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Text</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I would really like to know the criteria which...</td>\n",
       "      <td>[-5.62713146e-02  4.19251900e-03 -5.34271896e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Just wondered which airline would give any sor...</td>\n",
       "      <td>[ 5.21067306e-02  1.28700314e-02 -6.05350286e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Do they offer lunch or should we eat outside?</td>\n",
       "      <td>[ 2.18346287e-02  1.04145192e-01  7.76744559e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>When I have received my online ticket my surna...</td>\n",
       "      <td>[-3.91793856e-03 -6.24594428e-02 -3.84225533e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>will we be classed as transit passengers and t...</td>\n",
       "      <td>[ 7.88998529e-02 -5.62446974e-02 -2.45206114e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18180</th>\n",
       "      <td>31946</td>\n",
       "      <td>Our cable is not working. Is this something yo...</td>\n",
       "      <td>[ 1.91644579e-02 -6.11143559e-02  2.03925353e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18181</th>\n",
       "      <td>31947</td>\n",
       "      <td>I just got the service installed on 10/31/15 I...</td>\n",
       "      <td>[-5.31504191e-02 -9.80995689e-03  6.49894178e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18182</th>\n",
       "      <td>31949</td>\n",
       "      <td>my email does not send or receive very well. T...</td>\n",
       "      <td>[-1.13274930e-02 -3.12204901e-02  8.03747699e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18183</th>\n",
       "      <td>31950</td>\n",
       "      <td>where r business locations near cass city Mich...</td>\n",
       "      <td>[ 5.42873256e-02 -7.12359697e-02 -4.47087847e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18184</th>\n",
       "      <td>31951</td>\n",
       "      <td>why my internet speed is only 16.2 Mbps when y...</td>\n",
       "      <td>[ 5.80310076e-02  7.12981373e-02  3.82964611e-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18185 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                               Text  \\\n",
       "0               0  I would really like to know the criteria which...   \n",
       "1               3  Just wondered which airline would give any sor...   \n",
       "2               4      Do they offer lunch or should we eat outside?   \n",
       "3               5  When I have received my online ticket my surna...   \n",
       "4               6  will we be classed as transit passengers and t...   \n",
       "...           ...                                                ...   \n",
       "18180       31946  Our cable is not working. Is this something yo...   \n",
       "18181       31947  I just got the service installed on 10/31/15 I...   \n",
       "18182       31949  my email does not send or receive very well. T...   \n",
       "18183       31950  where r business locations near cass city Mich...   \n",
       "18184       31951  why my internet speed is only 16.2 Mbps when y...   \n",
       "\n",
       "                                               embedding  \n",
       "0      [-5.62713146e-02  4.19251900e-03 -5.34271896e-...  \n",
       "1      [ 5.21067306e-02  1.28700314e-02 -6.05350286e-...  \n",
       "2      [ 2.18346287e-02  1.04145192e-01  7.76744559e-...  \n",
       "3      [-3.91793856e-03 -6.24594428e-02 -3.84225533e-...  \n",
       "4      [ 7.88998529e-02 -5.62446974e-02 -2.45206114e-...  \n",
       "...                                                  ...  \n",
       "18180  [ 1.91644579e-02 -6.11143559e-02  2.03925353e-...  \n",
       "18181  [-5.31504191e-02 -9.80995689e-03  6.49894178e-...  \n",
       "18182  [-1.13274930e-02 -3.12204901e-02  8.03747699e-...  \n",
       "18183  [ 5.42873256e-02 -7.12359697e-02 -4.47087847e-...  \n",
       "18184  [ 5.80310076e-02  7.12981373e-02  3.82964611e-...  \n",
       "\n",
       "[18185 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8aaa62a5-252a-45fa-8bb9-302626d76095",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_clusters(message_embeddings,\n",
    "                      n_neighbors,\n",
    "                      n_components, \n",
    "                      min_cluster_size,\n",
    "                      random_state = None):\n",
    "    \"\"\"\n",
    "    Generate HDBSCAN cluster object after reducing embedding dimensionality with UMAP\n",
    "    \"\"\"\n",
    "    \n",
    "    umap_embeddings = (umap.UMAP(n_neighbors=n_neighbors, \n",
    "                                n_components=n_components, \n",
    "                                metric='cosine', \n",
    "                                random_state=random_state)\n",
    "                            .fit_transform(message_embeddings))\n",
    "\n",
    "    clusters = hdbscan.HDBSCAN(min_cluster_size = min_cluster_size,\n",
    "                               metric='euclidean', \n",
    "                               cluster_selection_method='eom').fit(umap_embeddings)\n",
    "\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4e68e2e-312b-4d54-aade-2ecb882cf841",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_clusters(clusters, prob_threshold = 0.05):\n",
    "    \"\"\"\n",
    "    Returns the label count and cost of a given cluster supplied from running hdbscan\n",
    "    \"\"\"\n",
    "    \n",
    "    cluster_labels = clusters.labels_\n",
    "    label_count = len(np.unique(cluster_labels))\n",
    "    total_num = len(clusters.labels_)\n",
    "    cost = (np.count_nonzero(clusters.probabilities_ < prob_threshold)/total_num)\n",
    "    \n",
    "    return label_count, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ee9e86c-a392-42d3-89f7-a6e48fe3b972",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_search(embeddings, space, num_evals):\n",
    "    \"\"\"\n",
    "    Randomly search hyperparameter space and limited number of times \n",
    "    and return a summary of the results\n",
    "    \"\"\"\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for i in range(num_evals):\n",
    "        n_neighbors = random.choice(space['n_neighbors'])\n",
    "        n_components = random.choice(space['n_components'])\n",
    "        min_cluster_size = random.choice(space['min_cluster_size'])\n",
    "        \n",
    "        clusters = generate_clusters(embeddings, \n",
    "                                     n_neighbors = n_neighbors, \n",
    "                                     n_components = n_components, \n",
    "                                     min_cluster_size = min_cluster_size, \n",
    "                                     random_state = 42)\n",
    "    \n",
    "        label_count, cost = score_clusters(clusters, prob_threshold = 0.05)\n",
    "                \n",
    "        results.append([i, n_neighbors, n_components, min_cluster_size, \n",
    "                        label_count, cost])\n",
    "    \n",
    "    result_df = pd.DataFrame(results, columns=['run_id', 'n_neighbors', 'n_components', \n",
    "                                               'min_cluster_size', 'label_count', 'cost'])\n",
    "    \n",
    "    return result_df.sort_values(by='cost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0724863a-9eb6-4f4d-b88b-0aa07179034b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MarcoOdore\\anaconda3\\lib\\site-packages\\umap\\umap_.py:1943: UserWarning: n_jobs value -1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(f\"n_jobs value {self.n_jobs} overridden to 1 by setting random_state. Use no seed for parallelism.\")\n",
      "C:\\Users\\MarcoOdore\\anaconda3\\lib\\site-packages\\umap\\umap_.py:1943: UserWarning: n_jobs value -1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(f\"n_jobs value {self.n_jobs} overridden to 1 by setting random_state. Use no seed for parallelism.\")\n",
      "C:\\Users\\MarcoOdore\\anaconda3\\lib\\site-packages\\umap\\umap_.py:1943: UserWarning: n_jobs value -1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(f\"n_jobs value {self.n_jobs} overridden to 1 by setting random_state. Use no seed for parallelism.\")\n"
     ]
    }
   ],
   "source": [
    "space = {\n",
    "    \"n_neighbors\": range(100, 150),\n",
    "    \"n_components\": range(3, 10),\n",
    "    \"min_cluster_size\": range(100, 150),\n",
    "    \"random_state\": 42\n",
    "}\n",
    "embeddings = df['embedding'].apply(lambda x: \n",
    "                                   np.fromstring(\n",
    "                                   x.replace('\\n','')\n",
    "                                    .replace('[','')\n",
    "                                    .replace(']','')\n",
    "                                    .replace('  ',' '), sep=' '))\n",
    "embeddings = [np.array(v, dtype='float') for v in embeddings]\n",
    "random_use = random_search(embeddings, space, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58e17a2-d02c-46a3-98f1-661498150a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916f59e9-7deb-4d4a-992e-dd8b3ce245a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_labels(category_docs):\n",
    "    \"\"\"\n",
    "    Extract labels from documents in the same cluster by concatenating\n",
    "    most common verbs, ojects, and nouns\n",
    "    \"\"\"\n",
    "\n",
    "    verbs = []\n",
    "    dobjs = []\n",
    "    nouns = []\n",
    "    adjs = []\n",
    "    \n",
    "    verb = ''\n",
    "    dobj = ''\n",
    "    noun1 = ''\n",
    "    noun2 = ''\n",
    "\n",
    "    # for each document, append verbs, dobs, nouns, and adjectives to \n",
    "    # running lists for whole cluster\n",
    "    for i in range(len(category_docs)):\n",
    "        doc = nlp(category_docs[i])\n",
    "        for token in doc:\n",
    "            if token.is_stop==False:\n",
    "                if token.dep_ == 'ROOT':\n",
    "                    verbs.append(token.text.lower())\n",
    "\n",
    "                elif token.dep_=='dobj':\n",
    "                    dobjs.append(token.lemma_.lower())\n",
    "\n",
    "                elif token.pos_=='NOUN':\n",
    "                    nouns.append(token.lemma_.lower())\n",
    "                    \n",
    "                elif token.pos_=='ADJ':\n",
    "                    adjs.append(token.lemma_.lower())\n",
    "    \n",
    "    # take most common words of each form\n",
    "    if len(verbs) > 0:\n",
    "        verb = most_common(verbs, 1)[0][0]\n",
    "    \n",
    "    if len(dobjs) > 0:\n",
    "        dobj = most_common(dobjs, 1)[0][0]\n",
    "    \n",
    "    if len(nouns) > 0:\n",
    "        noun1 = most_common(nouns, 1)[0][0]\n",
    "    \n",
    "    if len(set(nouns)) > 1:\n",
    "        noun2 = most_common(nouns, 2)[1][0]\n",
    "    \n",
    "    # concatenate the most common verb-dobj-noun1-noun2 (if they exist)\n",
    "    label_words = [verb, dobj]\n",
    "    \n",
    "    for word in [noun1, noun2]:\n",
    "        if word not in label_words:\n",
    "            label_words.append(word)\n",
    "    \n",
    "    if '' in label_words:\n",
    "        label_words.remove('')\n",
    "    \n",
    "    label = '_'.join(label_words)\n",
    "    \n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88010ab8-0291-481d-9ccf-a3eb663b6ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f880f73-e53b-472f-93f3-45592cf4e632",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
